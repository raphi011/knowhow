---
phase: 01-foundation
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - internal/embedding/ollama.go
  - internal/embedding/ollama_test.go
autonomous: true

must_haves:
  truths:
    - "Ollama client generates embeddings from text input"
    - "Embeddings are exactly 384 dimensions"
    - "Batch embedding works for multiple texts"
    - "Integration test passes with running Ollama instance"
  artifacts:
    - path: "internal/embedding/ollama.go"
      provides: "Ollama embedding client"
      contains: "type Client struct"
      exports: ["NewClient", "Embed", "EmbedBatch"]
    - path: "internal/embedding/ollama_test.go"
      provides: "Integration tests for Ollama embeddings"
      contains: "func TestEmbed"
  key_links:
    - from: "internal/embedding/ollama.go"
      to: "ollama/ollama/api"
      via: "api.ClientFromEnvironment"
      pattern: "api\\.ClientFromEnvironment"
---

<objective>
Implement Ollama embedding client that generates 384-dimensional vectors using the all-minilm:l6-v2 model, with strict dimension verification.

Purpose: Embeddings are critical for semantic search - dimension mismatch will break HNSW indices.
Output: Working Ollama client with dimension verification and integration tests.
</objective>

<execution_context>
@/Users/raphaelgruber/.claude/get-shit-done/workflows/execute-plan.md
@/Users/raphaelgruber/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Ollama embedding client</name>
  <files>internal/embedding/ollama.go</files>
  <action>
Create Ollama client using the official ollama/api package. CRITICAL: Verify embedding dimension is exactly 384.

```go
// internal/embedding/ollama.go
package embedding

import (
    "context"
    "fmt"

    "github.com/ollama/ollama/api"
)

const (
    // DefaultModel is the embedding model that produces 384-dimensional vectors.
    // CRITICAL: This MUST match the HNSW index dimension in SurrealDB schema.
    DefaultModel = "all-minilm:l6-v2"

    // ExpectedDimension is the required embedding dimension.
    // Mismatch will cause HNSW index queries to fail.
    ExpectedDimension = 384
)

// Client wraps the Ollama API for embedding generation.
type Client struct {
    client *api.Client
    model  string
}

// NewClient creates a new Ollama embedding client.
// If model is empty, uses DefaultModel (all-minilm:l6-v2).
// Uses OLLAMA_HOST environment variable for server URL (defaults to http://localhost:11434).
func NewClient(model string) (*Client, error) {
    if model == "" {
        model = DefaultModel
    }

    client, err := api.ClientFromEnvironment()
    if err != nil {
        return nil, fmt.Errorf("create ollama client: %w", err)
    }

    return &Client{client: client, model: model}, nil
}

// NewClientWithHost creates a client with explicit host (for testing).
func NewClientWithHost(host, model string) (*Client, error) {
    if model == "" {
        model = DefaultModel
    }

    client := api.NewClient(nil, nil)
    // Note: api.NewClient uses OLLAMA_HOST env var, to override we'd need custom http.Client
    // For now, rely on environment variable

    return &Client{client: client, model: model}, nil
}

// Model returns the configured embedding model name.
func (c *Client) Model() string {
    return c.model
}

// Embed generates an embedding vector for the given text.
// Returns exactly 384-dimensional float32 vector or error if dimension mismatch.
func (c *Client) Embed(ctx context.Context, text string) ([]float32, error) {
    resp, err := c.client.Embed(ctx, &api.EmbedRequest{
        Model: c.model,
        Input: text,
    })
    if err != nil {
        return nil, fmt.Errorf("embed: %w", err)
    }

    if len(resp.Embeddings) == 0 {
        return nil, fmt.Errorf("no embeddings returned")
    }

    embedding := resp.Embeddings[0]
    if len(embedding) != ExpectedDimension {
        return nil, fmt.Errorf("dimension mismatch: got %d, want %d (model: %s)",
            len(embedding), ExpectedDimension, c.model)
    }

    return embedding, nil
}

// EmbedBatch generates embeddings for multiple texts in a single request.
// More efficient than multiple Embed calls for bulk operations.
// All embeddings are verified to be exactly 384 dimensions.
func (c *Client) EmbedBatch(ctx context.Context, texts []string) ([][]float32, error) {
    if len(texts) == 0 {
        return [][]float32{}, nil
    }

    resp, err := c.client.Embed(ctx, &api.EmbedRequest{
        Model: c.model,
        Input: texts,
    })
    if err != nil {
        return nil, fmt.Errorf("embed batch: %w", err)
    }

    if len(resp.Embeddings) != len(texts) {
        return nil, fmt.Errorf("embedding count mismatch: got %d, want %d",
            len(resp.Embeddings), len(texts))
    }

    // Verify all dimensions
    for i, emb := range resp.Embeddings {
        if len(emb) != ExpectedDimension {
            return nil, fmt.Errorf("embedding %d dimension mismatch: got %d, want %d",
                i, len(emb), ExpectedDimension)
        }
    }

    return resp.Embeddings, nil
}

// EmbedWithTruncation embeds text, truncating if necessary for very long inputs.
// Ollama models have context limits; this provides a safe wrapper.
func (c *Client) EmbedWithTruncation(ctx context.Context, text string, maxTokens int) ([]float32, error) {
    // Simple truncation: estimate ~4 chars per token
    maxChars := maxTokens * 4
    if len(text) > maxChars {
        text = text[:maxChars]
    }
    return c.Embed(ctx, text)
}
```

CRITICAL requirements:
- Use `[]float32` not `[]float64` (Ollama returns float32, saves memory)
- ALWAYS verify dimension == 384 before returning
- Use api.ClientFromEnvironment() to respect OLLAMA_HOST env var
  </action>
  <verify>
`go build ./internal/embedding/...` compiles without errors
  </verify>
  <done>Client struct exists with NewClient, Embed, EmbedBatch, EmbedWithTruncation methods and 384-dim verification</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests</name>
  <files>internal/embedding/ollama_test.go</files>
  <action>
Create integration tests that verify embedding generation and dimension.
Tests require a running Ollama instance with all-minilm:l6-v2 model pulled.

```go
// internal/embedding/ollama_test.go
package embedding_test

import (
    "context"
    "testing"
    "time"

    "github.com/raphaelgruber/memcp-go/internal/embedding"
    "github.com/stretchr/testify/assert"
    "github.com/stretchr/testify/require"
)

func TestNewClient(t *testing.T) {
    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client with default model")
    assert.Equal(t, embedding.DefaultModel, client.Model())
}

func TestNewClientCustomModel(t *testing.T) {
    client, err := embedding.NewClient("custom-model")
    require.NoError(t, err, "should create client with custom model")
    assert.Equal(t, "custom-model", client.Model())
}

func TestEmbed(t *testing.T) {
    if testing.Short() {
        t.Skip("skipping integration test in short mode")
    }

    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client")

    emb, err := client.Embed(ctx, "This is a test sentence for embedding.")
    require.NoError(t, err, "should generate embedding")

    // CRITICAL: Verify dimension is exactly 384
    assert.Len(t, emb, embedding.ExpectedDimension,
        "embedding must be exactly %d dimensions", embedding.ExpectedDimension)

    // Verify values are reasonable (not all zeros, within normal range)
    var sum float32
    for _, v := range emb {
        sum += v * v
    }
    assert.Greater(t, sum, float32(0.1), "embedding should have non-trivial values")
}

func TestEmbedBatch(t *testing.T) {
    if testing.Short() {
        t.Skip("skipping integration test in short mode")
    }

    ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
    defer cancel()

    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client")

    texts := []string{
        "First test sentence.",
        "Second test sentence with different content.",
        "Third sentence about something else entirely.",
    }

    embeddings, err := client.EmbedBatch(ctx, texts)
    require.NoError(t, err, "should generate batch embeddings")

    assert.Len(t, embeddings, len(texts), "should return one embedding per text")

    for i, emb := range embeddings {
        assert.Len(t, emb, embedding.ExpectedDimension,
            "embedding %d must be exactly %d dimensions", i, embedding.ExpectedDimension)
    }
}

func TestEmbedBatchEmpty(t *testing.T) {
    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client")

    ctx := context.Background()
    embeddings, err := client.EmbedBatch(ctx, []string{})
    require.NoError(t, err, "should handle empty batch")
    assert.Len(t, embeddings, 0, "should return empty slice")
}

func TestEmbedSimilarity(t *testing.T) {
    if testing.Short() {
        t.Skip("skipping integration test in short mode")
    }

    ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
    defer cancel()

    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client")

    // Similar sentences should have high cosine similarity
    emb1, err := client.Embed(ctx, "The cat sat on the mat.")
    require.NoError(t, err)

    emb2, err := client.Embed(ctx, "A cat was sitting on a mat.")
    require.NoError(t, err)

    // Different sentence
    emb3, err := client.Embed(ctx, "Database query optimization techniques.")
    require.NoError(t, err)

    sim12 := cosineSimilarity(emb1, emb2)
    sim13 := cosineSimilarity(emb1, emb3)

    t.Logf("Similarity (similar sentences): %.4f", sim12)
    t.Logf("Similarity (different topics): %.4f", sim13)

    assert.Greater(t, sim12, sim13, "similar sentences should have higher similarity than different topics")
    assert.Greater(t, sim12, float32(0.7), "similar sentences should have >0.7 similarity")
}

func TestEmbedWithTruncation(t *testing.T) {
    if testing.Short() {
        t.Skip("skipping integration test in short mode")
    }

    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    client, err := embedding.NewClient("")
    require.NoError(t, err, "should create client")

    // Create a very long text
    longText := ""
    for i := 0; i < 1000; i++ {
        longText += "This is a repeating sentence to make a very long text. "
    }

    emb, err := client.EmbedWithTruncation(ctx, longText, 512)
    require.NoError(t, err, "should embed with truncation")
    assert.Len(t, emb, embedding.ExpectedDimension)
}

// cosineSimilarity calculates cosine similarity between two vectors.
func cosineSimilarity(a, b []float32) float32 {
    if len(a) != len(b) {
        return 0
    }

    var dotProduct, normA, normB float32
    for i := range a {
        dotProduct += a[i] * b[i]
        normA += a[i] * a[i]
        normB += b[i] * b[i]
    }

    if normA == 0 || normB == 0 {
        return 0
    }

    return dotProduct / (sqrt(normA) * sqrt(normB))
}

func sqrt(x float32) float32 {
    // Simple Newton-Raphson for float32
    if x <= 0 {
        return 0
    }
    z := x
    for i := 0; i < 10; i++ {
        z = (z + x/z) / 2
    }
    return z
}
```

**Pre-test setup required:**
```bash
# Pull the embedding model before running tests
ollama pull all-minilm:l6-v2
```
  </action>
  <verify>
`go build ./internal/embedding/...` compiles without errors
`go test ./internal/embedding/... -short` (skip integration tests)
With Ollama running: `go test ./internal/embedding/... -v`
  </verify>
  <done>Integration tests verify embedding generation, 384-dim output, batch processing, and similarity calculation</done>
</task>

</tasks>

<verification>
```bash
cd /Users/raphaelgruber/Git/memcp/migrate-to-go

# Build verification
go build ./internal/embedding/...

# Static analysis
go vet ./internal/embedding/...

# Unit tests (no Ollama needed)
go test ./internal/embedding/... -short

# Integration tests (requires Ollama running with model)
# Start Ollama first and pull model: ollama pull all-minilm:l6-v2
go test ./internal/embedding/... -v

# Verify dimension explicitly
go test ./internal/embedding/... -v -run TestEmbed
```
</verification>

<success_criteria>
1. `internal/embedding/ollama.go` exists with NewClient, Embed, EmbedBatch methods
2. Client uses api.ClientFromEnvironment() to respect OLLAMA_HOST
3. ALL embedding methods verify dimension == 384 before returning
4. EmbedBatch handles empty input gracefully
5. Integration tests pass with running Ollama instance
6. Similarity test confirms embeddings capture semantic meaning
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
